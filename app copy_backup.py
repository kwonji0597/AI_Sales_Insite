# ì‹¤í–‰: streamlit run app.py

import streamlit as st
import os
import re
import pandas as pd  # ğŸ†• ì¶”ê°€
import plotly.express as px  # ğŸ†• ì¶”ê°€ pip install pandas plotly or uv add pandas plotly
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity #í•„ìˆ˜
from langchain_tavily import TavilySearch
from collections import defaultdict 
from sqlalchemy import text
from external_utils.date_keywords import get_date_keywords
from pipelines.query_pipeline import get_all_inventory_from_db
from pipelines.connect_db_engine import create_db_engine, connection_db
from pipelines.vision_pipeline import (
    classify_product_image, 
    save_classification_to_db, 
    get_recent_classifications
)


# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
VISION_API_KEY = os.getenv("VISION_API_KEY")

engine = create_db_engine()

# ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOpenAI(model_name="gpt-4o", openai_api_key=OPENAI_API_KEY, temperature=0.3)
tavily = TavilySearch(api_key=TAVILY_API_KEY) if TAVILY_API_KEY else None
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=OPENAI_API_KEY)

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def get_weather_and_trends(user_question: str):
    if not tavily:
        return "ë‚ ì”¨ ì •ë³´ ì—†ìŒ", "íŠ¸ë Œë“œ ì •ë³´ ì—†ìŒ"
    
    weather_query, trend_query = get_date_keywords(user_question)
    weather_info = tavily.run(weather_query) # TAVILY ì‚¬ìš©
    trend_info = tavily.run(trend_query)
    return weather_info, trend_info


def inventory_match_via_embedding(cleaned_gpt_product_names, similarity_threshold=0.35):

    # ì „ì²´ DB ì¬ê³  ë”•ë…€ë„ˆë¦¬
    db_inventory_dict = get_all_inventory_from_db()
    print(f"DB ì¬ê³  ì •ë³´: : {db_inventory_dict} ")
    result = defaultdict(list)

    if not db_inventory_dict:
        for gpt_name in cleaned_gpt_product_names:
            result[gpt_name] = [(gpt_name, 0)]
        return result
    
    db_names = list(db_inventory_dict.keys())
    print(f"DB ìƒí’ˆëª… ëª©ë¡: : {db_names} ")

    # DB ìƒí’ˆëª…ë“¤ì˜ ì„ë² ë”© ìƒì„±
    db_embeddings = embedding_model.embed_documents(db_names)
    
    # ê° GPT ì¶”ì²œ ìƒí’ˆì— ëŒ€í•´ ë§¤ì¹­ ìˆ˜í–‰ (gpt_name(gptì—ì„œ ë°›ì€ ì¶”ì²œìƒí’ˆ))
    for gpt_name in cleaned_gpt_product_names:

        # gpt_name ì„ë² ë”©
        gpt_embedding = embedding_model.embed_query(gpt_name)

        # ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity([gpt_embedding], db_embeddings)[0]
        matched_items = []

        for i, sim in enumerate(similarities):

            # ğŸ”§ ìˆ˜ì •: í•˜ë“œì½”ë”©ëœ 0.30ì„ ë§¤ê°œë³€ìˆ˜ë¡œ ë³€ê²½
            # if sim >= 0.3:  # ğŸ†• ì‚¬ìš©ì ì„¤ì • ìœ ì‚¬ë„ ì‚¬ìš©
            if sim >= similarity_threshold:  # ê¸°ì¡´: if sim >= 0.30:
                db_name = db_names[i]
                stock = db_inventory_dict[db_name]
                matched_items.append((db_name, stock))
                print(f"   âœ… ë§¤ì¹­: {gpt_name} â†’ {db_name} (ìœ ì‚¬ë„: {sim:.3f})")  # ğŸ†• ë§¤ì¹­ ë¡œê·¸


        if not matched_items:
            result[gpt_name] = [(gpt_name, 0)]
            print(f"   âŒ ë§¤ì¹­ ì‹¤íŒ¨: {gpt_name} (ìµœê³  ìœ ì‚¬ë„: {max(similarities):.3f})")  # ğŸ†• ì‹¤íŒ¨ ë¡œê·¸
        else:
            result[gpt_name] = matched_items

    return result


# ë‚ ì”¨ ë° íŠ¸ë Œë“œì— ë§ëŠ” ìƒí’ˆëª… ì¶”ì¶œ
def product_name_extract(user_question: str, weather_info: str, trend_info: str, similarity_threshold=0.3) -> dict:
    product_extraction_prompt = f"""
        ì‚¬ìš©ì ì§ˆë¬¸: {user_question}    
        ë‚ ì”¨ ì •ë³´: {weather_info}
        íŠ¸ë Œë“œ ì •ë³´: {trend_info}

        ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ìƒí’ˆëª…ì„ 5ê°œ ì œì‹œí•´ì£¼ì„¸ìš”.
        ìƒí’ˆëª…ë§Œ í•œ ì¤„ì”© ë‚˜ì—´í•´ ì£¼ì„¸ìš”.
        
        ì˜ˆì‹œ:
        - ë°©ìˆ˜ ìš°ì‚° : ë°©ìˆ˜ë¡œ ì²˜ë¦¬ëœ ìš°ì‚°
        - ì¬í¬ë¦¼ 
        - í…€ë¸”ëŸ¬
        - ì—ì½”ë°±
        - ë‹¤ì´ì–´ë¦¬
    """
    
    response = llm.invoke(product_extraction_prompt)
    response_text = response.content if hasattr(response, "content") else str(response)
    
    raw_product_names = [line.strip("-â€¢ ").strip() for line in response_text.split('\n') if line.strip()]
    cleaned_gpt_product_names = [re.sub(r"^[0-9]+[\.)]?\s*", "", name).replace(" ", "") for name in raw_product_names]

    return inventory_match_via_embedding(cleaned_gpt_product_names)
   
def generate_strategic(user_question: str, weather_info: str, trend_info: str, inventory_infos: dict):
    inventory_lines = []
    for gpt_name, db_matches in inventory_infos.items():
        if db_matches:
            for db_name, qty in db_matches:
                inventory_lines.append(f"{db_name} (ì¬ê³ : {qty}ê°œ)")
        else:
            inventory_lines.append(f"{gpt_name} (ì¬ê³ : 0ê°œ)")       
                                
    inventory_text = "\n".join(inventory_lines)

    return f"""
            ë„ˆëŠ” í™ˆì‡¼í•‘ ë°©ì†¡ ìƒí’ˆ ê¸°íš ì „ë¬¸ê°€ì•¼.

            ì‚¬ìš©ì ì§ˆë¬¸: '{user_question}'
            ë‚ ì”¨ ì •ë³´: {weather_info}
            íŠ¸ë Œë“œ ì •ë³´: {trend_info}

            [ì¶”ì²œ ìƒí’ˆë³„ ì¬ê³  ì •ë³´]
            {inventory_text}

            ìœ„ í˜•ì‹ìœ¼ë¡œ ë°©ì†¡ ì „ëµì„ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì¤˜.
            """

# Streamlit UI ì„¤ì •
st.set_page_config(page_title="ğŸ“Š AI ìƒí’ˆ íŒë§¤ Insite", layout="wide")
st.markdown("<h3 style='text-align: center;'>ğŸ“Š AI ìƒí’ˆ íŒë§¤ Insite</h3>", unsafe_allow_html=True)

# íƒ­ ìƒì„±
tabs = st.tabs(["Analysis Product Category", "Product Image Category", "AI Recommendation"])

# ì¹´í…Œê³ ë¦¬ ìƒí’ˆ ë¶„ì„
with tabs[0]:
    st.header("ğŸ§  GPT ê¸°ë°˜ ìë™ ì¹´í…Œê³ ë¦¬í™” ë¶„ì„")
    
    # ========================================
    # 1ï¸âƒ£ ê¸°ë³¸ í†µê³„ ëŒ€ì‹œë³´ë“œ (MVP í•µì‹¬ ê¸°ëŠ¥)
    # ========================================
    col1, col2, col3, col4 = st.columns(4)
    
    try:
        # DBì—ì„œ ê¸°ë³¸ í†µê³„ ì¡°íšŒ
        if engine:
            with engine.connect() as conn:
                # ì „ì²´ ë¶„ë¥˜ ê±´ìˆ˜
                total_query = text("SELECT COUNT(*) FROM product_classifications")
                total_count = conn.execute(total_query).fetchone()[0]
                
                # ì¹´í…Œê³ ë¦¬ ì¢…ë¥˜ ìˆ˜
                category_query = text("SELECT COUNT(DISTINCT category) FROM product_classifications")
                category_count = conn.execute(category_query).fetchone()[0]
                
                # í‰ê·  ì‹ ë¢°ë„
                confidence_query = text("SELECT AVG(confidence_score) FROM product_classifications WHERE confidence_score IS NOT NULL")
                avg_confidence = conn.execute(confidence_query).fetchone()[0] or 0
                
                # ì˜¤ëŠ˜ ë¶„ë¥˜ ê±´ìˆ˜
                today_query = text("SELECT COUNT(*) FROM product_classifications WHERE DATE(created_at) = CURDATE()")
                today_count = conn.execute(today_query).fetchone()[0]
                
        else:
            # DB ì—°ê²° ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
            total_count, category_count, avg_confidence, today_count = 0, 0, 0, 0
            
    except Exception as e:
        st.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        total_count, category_count, avg_confidence, today_count = 0, 0, 0, 0
    
    # ë©”íŠ¸ë¦­ í‘œì‹œ
    with col1:
        st.metric("ğŸ“Š ì´ ë¶„ë¥˜ ê±´ìˆ˜", f"{total_count:,}")
    with col2:
        st.metric("ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ ì¢…ë¥˜", f"{category_count}")
    with col3:
        st.metric("ğŸ¯ í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.2f}" if avg_confidence else "0.00")
    with col4:
        st.metric("ğŸ“… ì˜¤ëŠ˜ ë¶„ë¥˜", f"{today_count}")
    
    st.divider()
    
    # ========================================
    # 2ï¸âƒ£ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬ ë¶„ì„ (ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸)
    # ========================================
    # col_left, col_right = st.columns([1, 1])
    # with col_left:
    st.subheader("ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ í˜„í™©")
    
    if st.button("ğŸ”„ ì¹´í…Œê³ ë¦¬ ë¶„í¬ ë¶„ì„"):
        try:
            with engine.connect() as conn:
                # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ì¿¼ë¦¬
                category_stats_query = text("""
                    SELECT 
                        category,category2, category3, tags, 
                        COUNT(*) as count,
                        AVG(confidence_score) as avg_confidence,
                        MAX(created_at) as last_classified
                    FROM product_classifications 
                    GROUP BY category,category2, category3, tags
                    ORDER BY count DESC
                """)
                
                result = conn.execute(category_stats_query).fetchall()
                
                if result:
                    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                    df = pd.DataFrame(result, columns=['ì¹´í…Œê³ ë¦¬', 'ì¹´í…Œê³ ë¦¬2', 'ì¹´í…Œê³ ë¦¬3', 'TAG', 'ë¶„ë¥˜ìˆ˜', 'í‰ê· ì‹ ë¢°ë„', 'ë§ˆì§€ë§‰ë¶„ë¥˜'])
                    
                    # ë°ì´í„° í‘œì‹œ
                    st.dataframe(
                        df.style.format({
                            'ë¶„ë¥˜ìˆ˜': '{:,}',
                            'í‰ê· ì‹ ë¢°ë„': '{:.2f}',
                            'ë§ˆì§€ë§‰ë¶„ë¥˜': lambda x: str(x)[:19] if x else ''
                        }),
                        use_container_width=True,
                        height=300
                    )
                    
                    # ê°„ë‹¨í•œ ì°¨íŠ¸ë„ í‘œì‹œ
                    fig = px.bar(
                        df.head(8), 
                        x='ì¹´í…Œê³ ë¦¬', 
                        y='ë¶„ë¥˜ìˆ˜',
                        title="ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ê±´ìˆ˜ (ìƒìœ„ 8ê°œ)",
                        color='í‰ê· ì‹ ë¢°ë„',
                        color_continuous_scale='Viridis'
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
                    
                else:
                    st.info("ğŸ“­ ë¶„ë¥˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
        except Exception as e:
            st.error(f"âŒ ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
    

# Product Image Category Tab (ê°œì„ ëœ DB ì €ì¥ ê¸°ëŠ¥)
with tabs[1]:
    st.subheader("ğŸ–¼ï¸ ìƒí’ˆ ì´ë¯¸ì§€ ë¶„ë¥˜")
    
    # DB ìƒíƒœ í™•ì¸
    db_status = connection_db()
    if db_status["success"]:
        st.success(f"âœ… {db_status['message']}")
    else:
        st.error(f"âŒ {db_status['error']}")
    
    # ì´ë¯¸ì§€ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=["jpg", "jpeg", "png"],
        help="JPG, PNG í˜•ì‹ë§Œ ì§€ì›"
    )
    
    if uploaded_file is not None:
        col1, col2 = st.columns(2)
        
        with col1:
            # ì´ë¯¸ì§€ í‘œì‹œ
            st.image(uploaded_file, caption=f"ì—…ë¡œë“œëœ ì´ë¯¸ì§€: {uploaded_file.name}", width=300)
            st.write(f"íŒŒì¼ í¬ê¸°: {uploaded_file.size:,} bytes")
        
        with col2:
            # ë¶„ë¥˜ ì‹¤í–‰
            if st.button("ğŸ” ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹¤í–‰", type="primary"):
                with st.spinner("ë¶„ë¥˜ ì¤‘..."):
                    try:
                        # ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹¤í–‰
                        result = classify_product_image(uploaded_file)

                        if "error" in result:
                            st.error(f"ë¶„ë¥˜ ì‹¤íŒ¨: {result['error']}")
                        else:
                            # ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
                            st.session_state.last_result = result
                            
                            # ê²°ê³¼ í‘œì‹œ
                            st.success("âœ… ë¶„ë¥˜ ì™„ë£Œ!")
                            
                            # ë©”íŠ¸ë¦­ í‘œì‹œ
                            col_a, col_b = st.columns(2)
                            with col_a:
                                st.metric("ì¹´í…Œê³ ë¦¬", result['category'])
                            with col_b:
                                st.metric("ì‹ ë¢°ë„", f"{result['confidence_score']:.2f}")
                            
                            # íƒœê·¸ í‘œì‹œ
                            st.write("**íƒœê·¸:**", " | ".join(result['tags']))
                            
                            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸
                            if result['extracted_text']:
                                st.write("**ì¶”ì¶œëœ ì •ë³´:**", result['extracted_text'])
                    
                    except Exception as e:
                        st.error(f"ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # DB ì €ì¥ ë²„íŠ¼ (ë¶„ë¥˜ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ)
            if 'last_result' in st.session_state and st.session_state.last_result.get('db_ready'):
                st.markdown("---")
                
                if st.button("ğŸ’¾ DBì— ì €ì¥", type="secondary"):
                    result = st.session_state.last_result
                    
                    with st.spinner("DB ì €ì¥ ì¤‘..."):
                        # DBì— ì €ì¥
                        save_result = save_classification_to_db(
                            result['image_id'],
                            result['category'],
                            result['category2'],
                            result['category3'],
                            result['confidence_score'],
                            result['extracted_text'],
                            result['tags']
                        )
                        
                        if save_result["success"]:
                            st.success(f"âœ… {save_result['message']}")
                            # ì €ì¥ í›„ ê²°ê³¼ í´ë¦¬ì–´
                            if 'last_result' in st.session_state:
                                del st.session_state.last_result
                            st.rerun()
                        else:
                            st.error(f"âŒ {save_result['error']}")

    # ìµœê·¼ ë¶„ë¥˜ íˆìŠ¤í† ë¦¬ (ê°„ë‹¨ ë²„ì „)
    if st.checkbox("ğŸ“ˆ ìµœê·¼ ë¶„ë¥˜ ê²°ê³¼ ë³´ê¸°"):
        recent_data = get_recent_classifications(limit=5)
        
        if recent_data:
            st.write("**ìµœê·¼ 5ê°œ ë¶„ë¥˜:**")
            for i, item in enumerate(recent_data, 1):
                st.write(f"{i}. **{item['category']}** (ì‹ ë¢°ë„: {item['confidence']:.2f}) - {item['created_at']}")
        else:
            st.info("ë¶„ë¥˜ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")


with tabs[2]:
    st.subheader("ğŸ¤– AI ìƒí’ˆíŒë§¤ ì „ëµ ì¶”ì²œ")
    
    # ğŸ†• ìœ ì‚¬ë„ ì¡°ì • UI ì¶”ê°€
    col_input, col_similarity = st.columns([3, 1])
    
    with col_input:
        user_question = st.text_input("ìƒí’ˆ ê¸°íš ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë‹¤ìŒì£¼ì— ì–´ë–¤ ìƒí’ˆì„ íŒë§¤í•˜ë©´ ì¢‹ì„ê¹Œ?)")
    
    with col_similarity:
        # ğŸ†• ìœ ì‚¬ë„ ìŠ¬ë¼ì´ë” ì¶”ê°€
        similarity_threshold = st.slider(
            "ğŸ¯ ìœ ì‚¬ë„ ì„ê³„ê°’", 
            min_value=0.1, 
            max_value=0.9, 
            value=0.3,  # ê¸°ë³¸ê°’ 0.3
            step=0.05,
            help="ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ìƒí’ˆì´ ë§¤ì¹­ë©ë‹ˆë‹¤"
        )
        # ğŸ†• ìœ ì‚¬ë„ ì„¤ëª… í‘œì‹œ
        if similarity_threshold < 0.3:
            st.caption("ğŸ” ëŠìŠ¨í•œ ë§¤ì¹­ (ë” ë§ì€ ìƒí’ˆ)")
        elif similarity_threshold > 0.6:
            st.caption("ğŸ¯ ì—„ê²©í•œ ë§¤ì¹­ (ì •í™•í•œ ìƒí’ˆ)")
        else:
            st.caption("âš–ï¸ ê· í˜•ì¡íŒ ë§¤ì¹­")

    if st.button("AI ìƒí’ˆíŒë§¤ ì „ëµ ì¶”ì²œ ë°›ê¸°") and user_question:
        with st.spinner("AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ë‚ ì”¨/íŠ¸ë Œë“œ ì •ë³´ ìˆ˜ì§‘
                weather_info, trend_info = get_weather_and_trends(user_question)
        
                # ğŸ”§ ìˆ˜ì •: ì‚¬ìš©ì ì„¤ì • ìœ ì‚¬ë„ë¥¼ ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬
                inventory_info = product_name_extract(
                    user_question, 
                    weather_info, 
                    trend_info, 
                    similarity_threshold  # ğŸ†• ì‚¬ìš©ì ì„¤ì • ìœ ì‚¬ë„ ì „ë‹¬
                )
                
                # ì „ëµ ìƒì„±
                final_prompt = generate_strategic(user_question, weather_info, trend_info, inventory_info)
                response = llm.invoke(final_prompt)
                print(f"ì „ëµ ìƒì„± ì‘ë‹µ ê²°ê³¼ : {response}")
                
                # ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.subheader("ğŸ“Š ì¶”ì²œ ìƒí’ˆ ë° ì¬ê³ ")
                    
                    # ğŸ†• ìœ ì‚¬ë„ ì„¤ì • ì •ë³´ í‘œì‹œ
                    st.info(f"ğŸ¯ ì„¤ì •ëœ ìœ ì‚¬ë„ ì„ê³„ê°’: {similarity_threshold:.2f}")
                    
                    # ğŸ†• ë§¤ì¹­ í†µê³„ ì¹´ìš´í„°
                    total_matches = 0
                    total_products = len(inventory_info)
                    
                    for gpt_name, matches in inventory_info.items():
                        st.write(f"**{gpt_name}**")
                        
                        if matches and matches[0][1] > 0:  # ì¬ê³ ê°€ ìˆëŠ” ê²½ìš°
                            for name, qty in matches:
                                if qty > 0:
                                    st.write(f"   âœ… {name} (ì¬ê³ : {qty}ê°œ)")
                                    total_matches += 1
                                else:
                                    st.write(f"   âŒ {name} (í’ˆì ˆ)")
                        else:
                            st.write(f"   âŒ ë§¤ì¹­ëœ ìƒí’ˆ ì—†ìŒ")
                    
                    # ğŸ†• ë§¤ì¹­ ì„±ê³µë¥  í‘œì‹œ
                    success_rate = (total_matches / total_products * 100) if total_products > 0 else 0
                    st.markdown("---")
                    st.metric(
                        "ğŸ“ˆ ë§¤ì¹­ ì„±ê³µë¥ ", 
                        f"{success_rate:.1f}%",
                        help=f"ì´ {total_products}ê°œ ìƒí’ˆ ì¤‘ {total_matches}ê°œ ë§¤ì¹­"
                    )
                    
                    # ğŸ†• ìœ ì‚¬ë„ ì¡°ì • ê°€ì´ë“œ
                    if success_rate < 50:
                        st.warning("ğŸ’¡ ë§¤ì¹­ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. ìœ ì‚¬ë„ ì„ê³„ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš”.")
                    elif success_rate > 80:
                        st.success("ğŸ¯ ë†’ì€ ë§¤ì¹­ë¥ ì…ë‹ˆë‹¤!")
                
                with col2:
                    st.subheader("ğŸ¯ AI ì¶”ì²œ ì „ëµ")
                    st.write(response.content)
            
            except Exception as e:
                st.error(f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")

    if "agent_result_raw" in st.session_state:
        st.info("ğŸ“„ ì¼ë°˜ ì‘ë‹µ")
        st.markdown(st.session_state.agent_result_raw)
                
# ì‚¬ì´ë“œë°” - ì‹œìŠ¤í…œ ìƒíƒœ
with st.sidebar:
    st.header("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
    
    # API í‚¤ ìƒíƒœ
    if OPENAI_API_KEY:
        st.success("âœ… OpenAI API")
    else:
        st.error("âŒ OpenAI API")
    
    # TAVILY_API
    if TAVILY_API_KEY:
        st.success("âœ… Tavily API")
    else:
        st.error("âŒ Tavily API")

    # Azure_ComputerVision
    if VISION_API_KEY:
        st.success("âœ… Azure Computer Vision API")
    else:
        st.error("âŒ Azure Computer Vision API")
    
    # DB ì—°ê²° í…ŒìŠ¤íŠ¸
    if st.button("DB ì—°ê²° í…ŒìŠ¤íŠ¸"):
        print("DB ì—°ê²° í…ŒìŠ¤íŠ¸")
        status = connection_db()
        print(f"status : {status}")
        if status["success"]:
            st.success(status["message"])
        else:
            st.error(status["error"])

    # ğŸ†• ìœ ì‚¬ë„ ê°€ì´ë“œ ì¶”ê°€
    st.markdown("---")
    st.header("ğŸ¯ ìœ ì‚¬ë„ ê°€ì´ë“œ")
    
    with st.expander("ğŸ“– ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ëª…"):
        st.write("""
        **ìœ ì‚¬ë„ ì„ê³„ê°’ì´ë€?**
        - AIê°€ ìƒí’ˆì„ ë§¤ì¹­í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ê¸°ì¤€
        - 0.1 ~ 0.9 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì„¤ì • ê°€ëŠ¥
        
        **ì¶”ì²œ ì„¤ì •:**
        - **0.1~0.3**: ëŠìŠ¨í•œ ë§¤ì¹­ (ë” ë§ì€ ìƒí’ˆ í‘œì‹œ)
        - **0.3~0.6**: ê· í˜•ì¡íŒ ë§¤ì¹­ (ê¶Œì¥)
        - **0.6~0.9**: ì—„ê²©í•œ ë§¤ì¹­ (ì •í™•í•œ ìƒí’ˆë§Œ)
        
        **ì‚¬ìš© íŒ:**
        - ë§¤ì¹­ë˜ëŠ” ìƒí’ˆì´ ë„ˆë¬´ ì ìœ¼ë©´ â†’ ê°’ì„ ë‚®ì¶”ì„¸ìš”
        - ê´€ë ¨ ì—†ëŠ” ìƒí’ˆì´ ë§ìœ¼ë©´ â†’ ê°’ì„ ë†’ì´ì„¸ìš”
        """)
